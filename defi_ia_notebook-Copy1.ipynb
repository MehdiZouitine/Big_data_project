{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9950,
     "status": "ok",
     "timestamp": 1603037507599,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "AXSTA0Hg1L05",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adil/anaconda3/envs/ma-gym/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizerFast, AutoModel, AdamW\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from transformers import BertModel, BertConfig,BertTokenizerFast, BertForSequenceClassification\n",
    "import mlflow\n",
    "from dataloader import NlpTrainDataset,NlpTestDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d10ac0b6465b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "mean([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4347,
     "status": "ok",
     "timestamp": 1603037525359,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "Jict38JE0GLJ"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "train_df = pd.read_json(DATA_PATH+\"/train.json\")\n",
    "test_df = pd.read_json(DATA_PATH+\"/test.json\")\n",
    "train_label = pd.read_csv(DATA_PATH+\"/train_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1603037531395,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "aY3LqdoF21U3"
   },
   "outputs": [],
   "source": [
    "train, val, train_labels, val_labels = train_test_split(train_df,train_label['Category'],test_size=0.2,stratify=train_label['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "a = NlpTrainDataset(val,val_labels,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adil/anaconda3/envs/ma-gym/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', return_dict=True,num_labels=28)\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "train_encoding = tokenizer.batch_encode_plus(train['description'].to_list(),max_length = 170\\\n",
    "                                              ,padding=True,truncation=True)\n",
    "val_encoding = tokenizer.batch_encode_plus(val['description'].to_list(),max_length = 170\\\n",
    "                                              ,padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1603037533061,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "Eb_H2z1v-ThR"
   },
   "outputs": [],
   "source": [
    "class NlpTrainDataset(Dataset):\n",
    "    def __init__(self,Id,labels,encodings):\n",
    "        self.labels = labels.tolist()\n",
    "        self.encodings = encodings\n",
    "        self.Id  = Id.to_list()\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['Id'] = self.Id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1603037536226,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "TipgG2nrXrgj",
    "outputId": "0dfc2038-0c3f-4cf4-ff9b-9292346ffc6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seq_len = [len(i.split()) for i in train['description']]\n",
    "\n",
    "# pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 48876,
     "status": "ok",
     "timestamp": 1603037586059,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "Wv7Ene96AcX3"
   },
   "outputs": [],
   "source": [
    "train_dataset = NlpTrainDataset(train['Id'],train_labels,train_encoding)\n",
    "val_dataset = NlpTrainDataset(val['Id'],val_labels,val_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1603034433059,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "ViKKlzRJRsXr"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1603034497768,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "RaJdExwpTELs"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1603034679744,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "jYtiIxIiTI-c",
    "outputId": "8f27cbe3-f4a2-4fb8-84fa-5c472867e9dd"
   },
   "outputs": [],
   "source": [
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels.values)\n",
    "\n",
    "# print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1603034704375,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "z3YMWmDUTdGk"
   },
   "outputs": [],
   "source": [
    "# weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# # # push to GPU\n",
    "# weights = weights.to(device)        \n",
    "\n",
    "# cross_entropy  = nn.CrossEntropyLoss(weight=weights)\n",
    "cross_entropy  = nn.CrossEntropyLoss()\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "hyperparameters = {'epochs':epochs,'batch_size': batch_size, 'lr':lr, 'eps':eps,'optimizer': optimizer_name,\n",
    "                   'loss': loss_name, 'alpha': alpha, 'gamma': gamma}\n",
    "modules= {'model':model,'optimizer':optimizer,'scheduler':scheduler,'loss':loss}\n",
    "\n",
    "# # number of training epochs\n",
    "epochs = 10\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=16)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True,num_workers=16)\n",
    "optimizer = AdamW(model.parameters(),lr = 5e-5,eps = 1e-8)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "alpha = 0.25\n",
    "gamma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HipQ8MD5UGYs"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "   \n",
    "  \n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    total_labels = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "\n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "#         for key,value in batch.items():\n",
    "#             batch[key] = batch[key].to(device)\n",
    "            \n",
    "        sent_id = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, attention_mask=mask)\n",
    "#         loss = cross_entropy(preds.logits, labels)\n",
    "        ce_loss = nn.functional.cross_entropy(preds.logits,labels, reduction='none') # important to add reduction='none' to keep per-batch-item loss\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = (alpha * (1-pt)**gamma * ce_loss).mean()\n",
    "        \n",
    "        # compute the loss between actual and predicted values\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.logits.detach().cpu().numpy()\n",
    "        \n",
    "        labels = labels.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "        total_labels+= labels\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "\n",
    "    # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "\n",
    "          # Report progress.\n",
    "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        sent_id = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, attention_mask=mask)\n",
    "            \n",
    "            # compute the validation loss between actual and predicted values\n",
    "#             loss = cross_entropy(preds.logits,labels)\n",
    "            ce_loss = nn.functional.cross_entropy(preds.logits,labels, reduction='none') # important to add reduction='none' to keep per-batch-item loss\n",
    "            pt = torch.exp(-ce_loss)\n",
    "            loss = (alpha * (1-pt)**gamma * ce_loss).mean()\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.logits.detach().cpu().numpy()\n",
    "            \n",
    "            labels = labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "\n",
    "            total_preds.append(preds)\n",
    "            total_labels+=labels\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adil/anaconda3/envs/ma-gym/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def track(hyperparameters,metrics,model,epoch):\n",
    "    if epoch == 0:\n",
    "        for key,value in hyperparameters.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "    for key,value in metrics.items():\n",
    "        log_metric(key=key, value=value, step=epoch)\n",
    "        mlflow.pytorch.log_model(model, 'model_checkpoint')\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "19yFAn75kWri",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 2.62 GiB already allocated; 17.62 MiB free; 2.70 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f2c7972de6fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e064200304e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m#         loss = cross_entropy(preds.logits, labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# important to add reduction='none' to keep per-batch-item loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m         )\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 )\n\u001b[1;32m    484\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         )\n\u001b[1;32m    404\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ma-gym/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 2.62 GiB already allocated; 17.62 MiB free; 2.70 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, train_pred, train_lab = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, val_pred, val_lab = evaluate()\n",
    "    \n",
    "    \n",
    "    res_train = np.argmax(train_pred,axis=1).tolist()\n",
    "    res_val = np.argmax(val_pred,axis=1).tolist()\n",
    "    \n",
    "    f1_train = f1_score(train_lab, res_train,average='macro')\n",
    "    f1_val = f1_score(val_lab, res_val,average='macro')\n",
    "    \n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "    track(hyperparameters,metrics,model,epoch)\n",
    "    \n",
    "#     scheduler.step()\n",
    "    torch.save(model.state_dict(), f'models/saved_weights_{epoch}_train_{train_loss:.3f}_valid_{valid_loss:.3f}.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}, Training f1 : {f1_train}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}, Validation f1 : {f1_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Loss: 0.172, Training f1 : 0.9270389230268575\n",
    "# Validation Loss: 0.846, Validation f1 : 0.803059109809948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f66c25665d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_losses)\n",
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sFrTIAKAkd6Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'models/saved_weights_3_train_0.058_valid_0.385.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NlpTrainDataset(Dataset):\n",
    "    def __init__(self,encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return {'input_ids' : item['input_ids'].to(device), 'attention_mask' : item['attention_mask'].to(device)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_id = val_encoding['input_ids']\n",
    "mask = val_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = NlpTrainDataset(val_encoding)\n",
    "val_dataloader = DataLoader(testdata, batch_size=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 701/701 [02:24<00:00,  4.85it/s]\n"
     ]
    }
   ],
   "source": [
    "total_preds = []\n",
    "for batch in tqdm(val_dataloader):\n",
    "    preds = model(batch['input_ids'], batch['attention_mask'])\n",
    "    preds = preds.logits.detach().cpu().numpy()\n",
    "    total_preds.append(preds)\n",
    "    del preds\n",
    "preds = np.argmax(np.concatenate(total_preds),axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9246907680463821"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(val_labels.to_list(), preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9250927496719135 b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoding = tokenizer.batch_encode_plus(test_df['description'].to_list(),max_length = 170\\\n",
    "                                             ,padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = NlpTrainDataset(test_encoding)\n",
    "test_dataloader = DataLoader(testdata, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 905/905 [03:04<00:00,  4.91it/s]\n"
     ]
    }
   ],
   "source": [
    "total_preds = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    preds = model(batch['input_ids'], batch['attention_mask'])\n",
    "    preds = preds.logits.detach().cpu().numpy()\n",
    "    total_preds.append(preds)\n",
    "    del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(np.concatenate(total_preds),axis=1)\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_df['Id']\n",
    "submission['Category'] = preds\n",
    "submission.to_csv('bertpotential2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOiFO7kH8BNJnrr5sQt7ela",
   "collapsed_sections": [],
   "mount_file_id": "1kUrM1YVCeGVysEaGY6DaOnx8EG1oho0T",
   "name": "defi_ia_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('ma-gym': conda)",
   "language": "python",
   "name": "python37964bitmagymcondad4f0966e43384e928899b2eef06108e5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "068aa434c73a48248a247bf3bb00219e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0869726f74204fe898f99523abcc1121": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de1a481186884024bd7157dfbb310b3e",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eea2477986584b27998809147e6516b6",
      "value": 440473133
     }
    },
    "307834e91d584b2f9d55e5d381d0d31c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34a342d97640460b908d872874c547c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e114e39bf66b4b92ad1465dd0ae76ea8",
      "placeholder": "",
      "style": "IPY_MODEL_6f200e0903b44bbea01df7dde02b9a65",
      "value": " 440M/440M [10:15&lt;00:00, 716kB/s]"
     }
    },
    "4b46df27e84343a6ac2a27847645a863": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "627719943ff94ab39c1f5560d3a0a1dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "681fdd42ad9448b68ad5b665dc6d1857": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0869726f74204fe898f99523abcc1121",
       "IPY_MODEL_34a342d97640460b908d872874c547c0"
      ],
      "layout": "IPY_MODEL_307834e91d584b2f9d55e5d381d0d31c"
     }
    },
    "6f200e0903b44bbea01df7dde02b9a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7859513cebd24a3eaab1cbd63da0e24c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9223b8a8577641e2b361437bc4e23555": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f67ebf385e09474db0b1b2817591944c",
      "placeholder": "",
      "style": "IPY_MODEL_627719943ff94ab39c1f5560d3a0a1dc",
      "value": " 433/433 [00:00&lt;00:00, 849B/s]"
     }
    },
    "d51ed6dc16d24ab491a6ec33d5ab7250": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_068aa434c73a48248a247bf3bb00219e",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b46df27e84343a6ac2a27847645a863",
      "value": 433
     }
    },
    "de1a481186884024bd7157dfbb310b3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e114e39bf66b4b92ad1465dd0ae76ea8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eea2477986584b27998809147e6516b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f20931b8c05142efaf97886e434435ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d51ed6dc16d24ab491a6ec33d5ab7250",
       "IPY_MODEL_9223b8a8577641e2b361437bc4e23555"
      ],
      "layout": "IPY_MODEL_7859513cebd24a3eaab1cbd63da0e24c"
     }
    },
    "f67ebf385e09474db0b1b2817591944c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
