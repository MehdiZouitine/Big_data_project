{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9950,
     "status": "ok",
     "timestamp": 1603037507599,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "AXSTA0Hg1L05",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,WeightedRandomSampler\n",
    "from transformers import BertModel, BertConfig,BertTokenizerFast, BertForSequenceClassification, AdamW,DistilBertModel, DistilBertTokenizerFast\n",
    "import mlflow\n",
    "from dataloader import NlpTrainDataset,NlpTestDataset,WeightedSubsetRandomSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau,StepLR\n",
    "from torch.optim import Adam\n",
    "from focal import FocalLoss, LinkedFocalLoss\n",
    "from train import learn\n",
    "from logger import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from crossentropy import HardNegCrossEntropy,LinkedCrossEntropy,LinkedHardNegCrossEntropy\n",
    "from tricks import seed_everything\n",
    "from model import BERT_clf\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4347,
     "status": "ok",
     "timestamp": 1603037525359,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "Jict38JE0GLJ"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "train_df = pd.read_json(DATA_PATH+\"/train.json\")\n",
    "test_df = pd.read_json(DATA_PATH+\"/test.json\")\n",
    "train_label = pd.read_csv(DATA_PATH+\"/train_label.csv\")\n",
    "train_df['gender'] = train_df.apply(lambda x: 1 if x['gender'] == 'M' else 0,axis=1)\n",
    "test_df['gender'] = test_df.apply(lambda x: 1 if x['gender'] == 'M' else 0,axis=1)\n",
    "\n",
    "train_df['description'] = train_df['description'].apply(lambda x : x.lower())\n",
    "test_df['description'] = test_df['description'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1603037531395,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "aY3LqdoF21U3"
   },
   "outputs": [],
   "source": [
    "train, val, train_labels, val_labels = train_test_split(train_df,train_label['Category'],test_size=0.2,stratify=train_label['Category'],random_state=7,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = DistilBertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "# bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = train_labels\n",
    "curr = pd.DataFrame(weight.value_counts())\n",
    "curr.columns = ['weights']\n",
    "curr['Category'] = curr.index\n",
    "n = 1/train_labels.shape[0]\n",
    "curr['weights'] *=n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # curr.loc[curr['Category']== 0,'weights'] *= 1.36\n",
    "# # curr.loc[curr['Category']== 3,'weights'] *= 1.34\n",
    "# # curr.loc[curr['Category']== 17,'weights'] *= 1.39\n",
    "# curr.loc[curr['Category']== 19,'weights'] *= n*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(train_labels)\n",
    "df_sample = tmp.merge(curr,on='Category',how='left')\n",
    "df_sample.index = tmp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample['weights'] = df_sample['weights'].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 48876,
     "status": "ok",
     "timestamp": 1603037586059,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "Wv7Ene96AcX3"
   },
   "outputs": [],
   "source": [
    "train_dataset = NlpTrainDataset(train,train_labels,tokenizer)\n",
    "val_dataset = NlpTrainDataset(val,val_labels,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156498    15056.000000\n",
       "162765        0.032236\n",
       "131747     9836.000000\n",
       "184514     3292.000000\n",
       "194511     3248.000000\n",
       "              ...     \n",
       "173283    15056.000000\n",
       "149177     3697.000000\n",
       "28914         0.032236\n",
       "78566         0.032236\n",
       "10131         0.032236\n",
       "Name: weights, Length: 173757, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = WeightedRandomSampler(df_sample['weights'].values, len(df_sample['weights'].values))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, sampler=train_sampler,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173757/173757 [05:43<00:00, 505.90it/s]\n"
     ]
    }
   ],
   "source": [
    "list_label = []\n",
    "for d in tqdm(train_dataloader):\n",
    "    list_label.append(d['labels'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26    24.745478\n",
       "20    14.843143\n",
       "14    11.036678\n",
       "6     10.404761\n",
       "11     9.306100\n",
       "22     7.444880\n",
       "3      5.813866\n",
       "8      3.041604\n",
       "24     2.341201\n",
       "16     2.139194\n",
       "5      1.483681\n",
       "15     1.258654\n",
       "1      1.175780\n",
       "13     1.163694\n",
       "18     1.130314\n",
       "25     0.802845\n",
       "9      0.713065\n",
       "27     0.335526\n",
       "12     0.191647\n",
       "0      0.143304\n",
       "17     0.139275\n",
       "23     0.075393\n",
       "7      0.073091\n",
       "2      0.061005\n",
       "10     0.048919\n",
       "21     0.044315\n",
       "4      0.042588\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.Series(np.array(list_label)).value_counts()/ len(list_label)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_epoch = len(list_label)\n",
    "list_label_norm = [(v/len_epoch) * 100 for v in list_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.010934811259402499: 56013,\n",
       "         0.0017265491462214472: 7316,\n",
       "         0.0034530982924428945: 9836,\n",
       "         0.004604131056590526: 5293,\n",
       "         0.007481712966959605: 3248,\n",
       "         0.01496342593391921: 15056,\n",
       "         0.006330680202811973: 9285,\n",
       "         0.002877581910369079: 3697,\n",
       "         0.013812393169771578: 4673,\n",
       "         0.010359294877328683: 3299,\n",
       "         0.008632745731107236: 3433,\n",
       "         0.008057229349033421: 10097,\n",
       "         0.011510327641476316: 11717,\n",
       "         0.012661360405623946: 8313,\n",
       "         0.009208262113181051: 4360,\n",
       "         0.009783778495254867: 1125,\n",
       "         0.014387909551845393: 2716,\n",
       "         0.013236876787697761: 774,\n",
       "         0.0011510327641476314: 755,\n",
       "         0.015538942315993025: 1830,\n",
       "         0.005179647438664342: 2497,\n",
       "         0.0005755163820738157: 3292,\n",
       "         0.0: 1198,\n",
       "         0.002302065528295263: 646,\n",
       "         0.006906196584885789: 1311,\n",
       "         0.005755163820738158: 665,\n",
       "         0.0040286146745167105: 686,\n",
       "         0.01208584402355013: 626})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(list_label_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "l=[]\n",
    "for a in train_dataloader:\n",
    "    l.append(a['labels'].item())\n",
    "    if k > 2000:\n",
    "        break\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(l,bins=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam([{'params': model.bert.parameters(),'lr':lr}],lr=lr_clf,eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1603034704375,
     "user": {
      "displayName": "Zouitine Mehdi",
      "photoUrl": "",
      "userId": "12448681489671159026"
     },
     "user_tz": -120
    },
    "id": "z3YMWmDUTdGk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "lr = 2e-5\n",
    "lr_clf = None\n",
    "eps = 1e-8\n",
    "alpha = None\n",
    "gamma = None\n",
    "gamma_scheduler = None\n",
    "freeze = False\n",
    "# link = {0:[3,19],3:[19,0,2], 7: [24], 11: [19], 23: [26], 24: [13,19],13:[24],17:[11],23:[26],2:[3]}\n",
    "link = {0:[3,19],3:[19], 7: [24],17:[11],23:[26],2:[3],24:[13]}\n",
    "alpha_link = 3\n",
    "optimizer_name = 'AdamW'\n",
    "top_k = None\n",
    "loss_name = 'LinkedCrossEntropy'\n",
    "scheduler_name = 'get_linear_schedule_with_warmup'\n",
    "# model = BERT_clf(bert,freeze = freeze)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', return_dict=True,num_labels=28)\n",
    "model = model.to(device)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "#optimizer = Adam(model.parameters(),lr=lr,eps=eps)\n",
    "#loss_function = FocalLoss(alpha=alpha,gamma=gamma)\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels.values)\n",
    "# weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "# weights = weights.to(device) \n",
    "#loss_function  = nn.CrossEntropyLoss()\n",
    "# loss_function = HardNegCrossEntropy(top_k=top_k)\n",
    "loss_function = LinkedCrossEntropy(alpha_link, link)\n",
    "#loss_function = LinkedHardNegCrossEntropy(alpha_link, link,top_k)\n",
    "#train_sampler = WeightedRandomSampler(df_sample['weights'].values, len(df_sample['weights'].values))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=1)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=1)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "num_warmup_steps = int(0.1*total_steps)\n",
    "\n",
    "\n",
    "#scheduler = StepLR(optimizer,  step_size=1, gamma=gamma_scheduler)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = num_warmup_steps,\n",
    "                                            num_training_steps = total_steps)\n",
    "tolerance = 20\n",
    "delta = 0.0005\n",
    "early_stopper = EarlyStopping(tolerance,delta)\n",
    "\n",
    "comment = 'retry best with seed'\n",
    "hyperparameters = {'epochs':epochs,'batch_size': batch_size, 'lr':lr,'lr_clf':lr_clf, 'eps':eps,\n",
    "                   'alpha': alpha, 'gamma': gamma, 'optimizer': optimizer_name,\n",
    "                   'loss': loss_name,'scheduler':scheduler_name,\n",
    "                   'tolerance_es': tolerance,'delta_es':delta,'gamma_scheduler':gamma_scheduler,'top_k':top_k,\n",
    "                   'num_warmup': num_warmup_steps,'freeze':freeze,\n",
    "                   'alpha_link':alpha_link,'comment':comment}\n",
    "\n",
    "modules= {'model':model,'optimizer':optimizer,'scheduler':scheduler,\n",
    "          'loss_function':loss_function,'device': device,'early_stopper':early_stopper}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 3\n",
      "  Batch    50  of  5,430.\n",
      "  Batch   100  of  5,430.\n",
      "  Batch   150  of  5,430.\n",
      "  Batch   200  of  5,430.\n",
      "  Batch   250  of  5,430.\n",
      "  Batch   300  of  5,430.\n",
      "  Batch   350  of  5,430.\n",
      "  Batch   400  of  5,430.\n",
      "  Batch   450  of  5,430.\n",
      "  Batch   500  of  5,430.\n",
      "  Batch   550  of  5,430.\n",
      "  Batch   600  of  5,430.\n",
      "  Batch   650  of  5,430.\n",
      "  Batch   700  of  5,430.\n",
      "  Batch   750  of  5,430.\n",
      "  Batch   800  of  5,430.\n",
      "  Batch   850  of  5,430.\n",
      "  Batch   900  of  5,430.\n",
      "  Batch   950  of  5,430.\n",
      "  Batch 1,000  of  5,430.\n",
      "  Batch 1,050  of  5,430.\n",
      "  Batch 1,100  of  5,430.\n",
      "  Batch 1,150  of  5,430.\n",
      "  Batch 1,200  of  5,430.\n",
      "  Batch 1,250  of  5,430.\n",
      "  Batch 1,300  of  5,430.\n",
      "  Batch 1,350  of  5,430.\n",
      "  Batch 1,400  of  5,430.\n",
      "  Batch 1,450  of  5,430.\n",
      "  Batch 1,500  of  5,430.\n",
      "  Batch 1,550  of  5,430.\n",
      "  Batch 1,600  of  5,430.\n",
      "  Batch 1,650  of  5,430.\n",
      "  Batch 1,700  of  5,430.\n",
      "  Batch 1,750  of  5,430.\n",
      "  Batch 1,800  of  5,430.\n",
      "  Batch 1,850  of  5,430.\n",
      "  Batch 1,900  of  5,430.\n",
      "  Batch 1,950  of  5,430.\n",
      "  Batch 2,000  of  5,430.\n",
      "  Batch 2,050  of  5,430.\n",
      "  Batch 2,100  of  5,430.\n",
      "  Batch 2,150  of  5,430.\n",
      "  Batch 2,200  of  5,430.\n",
      "  Batch 2,250  of  5,430.\n",
      "  Batch 2,300  of  5,430.\n",
      "  Batch 2,350  of  5,430.\n",
      "  Batch 2,400  of  5,430.\n",
      "  Batch 2,450  of  5,430.\n",
      "  Batch 2,500  of  5,430.\n",
      "  Batch 2,550  of  5,430.\n",
      "  Batch 2,600  of  5,430.\n",
      "  Batch 2,650  of  5,430.\n",
      "  Batch 2,700  of  5,430.\n",
      "  Batch 2,750  of  5,430.\n",
      "  Batch 2,800  of  5,430.\n",
      "  Batch 2,850  of  5,430.\n",
      "  Batch 2,900  of  5,430.\n",
      "  Batch 2,950  of  5,430.\n",
      "  Batch 3,000  of  5,430.\n",
      "  Batch 3,050  of  5,430.\n",
      "  Batch 3,100  of  5,430.\n",
      "  Batch 3,150  of  5,430.\n",
      "  Batch 3,200  of  5,430.\n",
      "  Batch 3,250  of  5,430.\n",
      "  Batch 3,300  of  5,430.\n",
      "  Batch 3,350  of  5,430.\n",
      "  Batch 3,400  of  5,430.\n",
      "  Batch 3,450  of  5,430.\n",
      "  Batch 3,500  of  5,430.\n",
      "  Batch 3,550  of  5,430.\n",
      "  Batch 3,600  of  5,430.\n",
      "  Batch 3,650  of  5,430.\n",
      "  Batch 3,700  of  5,430.\n",
      "  Batch 3,750  of  5,430.\n",
      "  Batch 3,800  of  5,430.\n",
      "  Batch 3,850  of  5,430.\n",
      "  Batch 3,900  of  5,430.\n",
      "  Batch 3,950  of  5,430.\n",
      "  Batch 4,000  of  5,430.\n",
      "  Batch 4,050  of  5,430.\n",
      "  Batch 4,100  of  5,430.\n",
      "  Batch 4,150  of  5,430.\n",
      "  Batch 4,200  of  5,430.\n",
      "  Batch 4,250  of  5,430.\n",
      "  Batch 4,300  of  5,430.\n",
      "  Batch 4,350  of  5,430.\n",
      "  Batch 4,400  of  5,430.\n",
      "  Batch 4,450  of  5,430.\n",
      "  Batch 4,500  of  5,430.\n",
      "  Batch 4,550  of  5,430.\n",
      "  Batch 4,600  of  5,430.\n",
      "  Batch 4,650  of  5,430.\n",
      "  Batch 4,700  of  5,430.\n",
      "  Batch 4,750  of  5,430.\n",
      "  Batch 4,800  of  5,430.\n",
      "  Batch 4,850  of  5,430.\n",
      "  Batch 4,900  of  5,430.\n",
      "  Batch 4,950  of  5,430.\n",
      "  Batch 5,000  of  5,430.\n",
      "  Batch 5,050  of  5,430.\n",
      "  Batch 5,100  of  5,430.\n",
      "  Batch 5,150  of  5,430.\n",
      "  Batch 5,200  of  5,430.\n",
      "  Batch 5,250  of  5,430.\n",
      "  Batch 5,300  of  5,430.\n",
      "  Batch 5,350  of  5,430.\n",
      "  Batch 5,400  of  5,430.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of  5,430.\n",
      "  Batch   100  of  5,430.\n",
      "  Batch   150  of  5,430.\n",
      "  Batch   200  of  5,430.\n",
      "  Batch   250  of  5,430.\n",
      "  Batch   300  of  5,430.\n",
      "  Batch   350  of  5,430.\n",
      "  Batch   400  of  5,430.\n",
      "  Batch   450  of  5,430.\n",
      "  Batch   500  of  5,430.\n",
      "  Batch   550  of  5,430.\n",
      "  Batch   600  of  5,430.\n",
      "  Batch   650  of  5,430.\n",
      "  Batch   700  of  5,430.\n",
      "  Batch   750  of  5,430.\n",
      "  Batch   800  of  5,430.\n",
      "  Batch   850  of  5,430.\n",
      "  Batch   900  of  5,430.\n",
      "  Batch   950  of  5,430.\n",
      "  Batch 1,000  of  5,430.\n",
      "  Batch 1,050  of  5,430.\n",
      "  Batch 1,100  of  5,430.\n",
      "  Batch 1,150  of  5,430.\n",
      "  Batch 1,200  of  5,430.\n",
      "  Batch 1,250  of  5,430.\n",
      "  Batch 1,300  of  5,430.\n",
      "  Batch 1,350  of  5,430.\n",
      "  Batch 1,400  of  5,430.\n",
      "  Batch 1,450  of  5,430.\n",
      "  Batch 1,500  of  5,430.\n",
      "  Batch 1,550  of  5,430.\n",
      "  Batch 1,600  of  5,430.\n",
      "  Batch 1,650  of  5,430.\n",
      "  Batch 1,700  of  5,430.\n",
      "  Batch 1,750  of  5,430.\n",
      "  Batch 1,800  of  5,430.\n",
      "  Batch 1,850  of  5,430.\n",
      "  Batch 1,900  of  5,430.\n",
      "  Batch 1,950  of  5,430.\n",
      "  Batch 2,000  of  5,430.\n",
      "  Batch 2,050  of  5,430.\n",
      "  Batch 2,100  of  5,430.\n",
      "  Batch 2,150  of  5,430.\n",
      "  Batch 2,200  of  5,430.\n",
      "  Batch 2,250  of  5,430.\n",
      "  Batch 2,300  of  5,430.\n",
      "  Batch 2,350  of  5,430.\n",
      "  Batch 2,400  of  5,430.\n",
      "  Batch 2,450  of  5,430.\n",
      "  Batch 2,500  of  5,430.\n",
      "  Batch 2,550  of  5,430.\n",
      "  Batch 2,600  of  5,430.\n",
      "  Batch 2,650  of  5,430.\n",
      "  Batch 2,700  of  5,430.\n",
      "  Batch 2,750  of  5,430.\n",
      "  Batch 2,800  of  5,430.\n",
      "  Batch 2,850  of  5,430.\n",
      "  Batch 2,900  of  5,430.\n",
      "  Batch 2,950  of  5,430.\n",
      "  Batch 3,000  of  5,430.\n",
      "  Batch 3,050  of  5,430.\n",
      "  Batch 3,100  of  5,430.\n",
      "  Batch 3,150  of  5,430.\n",
      "  Batch 3,200  of  5,430.\n",
      "  Batch 3,250  of  5,430.\n",
      "  Batch 3,300  of  5,430.\n",
      "  Batch 3,350  of  5,430.\n",
      "  Batch 3,400  of  5,430.\n",
      "  Batch 3,450  of  5,430.\n",
      "  Batch 3,500  of  5,430.\n",
      "  Batch 3,550  of  5,430.\n",
      "  Batch 3,600  of  5,430.\n",
      "  Batch 3,650  of  5,430.\n",
      "  Batch 3,700  of  5,430.\n",
      "  Batch 3,750  of  5,430.\n",
      "  Batch 3,800  of  5,430.\n",
      "  Batch 3,850  of  5,430.\n",
      "  Batch 3,900  of  5,430.\n",
      "  Batch 3,950  of  5,430.\n",
      "  Batch 4,000  of  5,430.\n",
      "  Batch 4,050  of  5,430.\n",
      "  Batch 4,100  of  5,430.\n",
      "  Batch 4,150  of  5,430.\n",
      "  Batch 4,200  of  5,430.\n",
      "  Batch 4,250  of  5,430.\n",
      "  Batch 4,300  of  5,430.\n",
      "  Batch 4,350  of  5,430.\n",
      "  Batch 4,400  of  5,430.\n",
      "  Batch 4,450  of  5,430.\n",
      "  Batch 4,500  of  5,430.\n",
      "  Batch 4,550  of  5,430.\n",
      "  Batch 4,600  of  5,430.\n",
      "  Batch 4,650  of  5,430.\n",
      "  Batch 4,700  of  5,430.\n",
      "  Batch 4,750  of  5,430.\n",
      "  Batch 4,800  of  5,430.\n",
      "  Batch 4,850  of  5,430.\n",
      "  Batch 4,900  of  5,430.\n",
      "  Batch 4,950  of  5,430.\n",
      "  Batch 5,000  of  5,430.\n",
      "  Batch 5,050  of  5,430.\n",
      "  Batch 5,100  of  5,430.\n",
      "  Batch 5,150  of  5,430.\n",
      "  Batch 5,200  of  5,430.\n",
      "  Batch 5,250  of  5,430.\n",
      "  Batch 5,300  of  5,430.\n",
      "  Batch 5,350  of  5,430.\n",
      "  Batch 5,400  of  5,430.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of  1,358.\n",
      "  Batch   100  of  1,358.\n",
      "  Batch   150  of  1,358.\n",
      "  Batch   200  of  1,358.\n",
      "  Batch   250  of  1,358.\n",
      "  Batch   300  of  1,358.\n",
      "  Batch   350  of  1,358.\n",
      "  Batch   400  of  1,358.\n",
      "  Batch   450  of  1,358.\n",
      "  Batch   500  of  1,358.\n",
      "  Batch   550  of  1,358.\n",
      "  Batch   600  of  1,358.\n",
      "  Batch   650  of  1,358.\n",
      "  Batch   700  of  1,358.\n",
      "  Batch   750  of  1,358.\n",
      "  Batch   800  of  1,358.\n",
      "  Batch   850  of  1,358.\n",
      "  Batch   900  of  1,358.\n",
      "  Batch   950  of  1,358.\n",
      "  Batch 1,000  of  1,358.\n",
      "  Batch 1,050  of  1,358.\n",
      "  Batch 1,100  of  1,358.\n",
      "  Batch 1,150  of  1,358.\n",
      "  Batch 1,200  of  1,358.\n",
      "  Batch 1,250  of  1,358.\n",
      "  Batch 1,300  of  1,358.\n",
      "  Batch 1,350  of  1,358.\n",
      "saving ...\n",
      "\n",
      "Training Loss: 0.463, Training f1 : 0.8363609889377168\n",
      "Validation Loss: 0.582, Validation f1 : 0.7963561774008685\n",
      "Time for epoch 0 is 46.62769060929616 min\n",
      "\n",
      " Epoch 2 / 3\n",
      "  Batch    50  of  5,430.\n",
      "  Batch   100  of  5,430.\n",
      "  Batch   150  of  5,430.\n",
      "  Batch   200  of  5,430.\n",
      "  Batch   250  of  5,430.\n",
      "  Batch   300  of  5,430.\n",
      "  Batch   350  of  5,430.\n",
      "  Batch   400  of  5,430.\n",
      "  Batch   450  of  5,430.\n",
      "  Batch   500  of  5,430.\n",
      "  Batch   550  of  5,430.\n",
      "  Batch   600  of  5,430.\n",
      "  Batch   650  of  5,430.\n",
      "  Batch   700  of  5,430.\n",
      "  Batch   750  of  5,430.\n",
      "  Batch   800  of  5,430.\n",
      "  Batch   850  of  5,430.\n",
      "  Batch   900  of  5,430.\n",
      "  Batch   950  of  5,430.\n",
      "  Batch 1,000  of  5,430.\n",
      "  Batch 1,050  of  5,430.\n",
      "  Batch 1,100  of  5,430.\n",
      "  Batch 1,150  of  5,430.\n",
      "  Batch 1,200  of  5,430.\n",
      "  Batch 1,250  of  5,430.\n",
      "  Batch 1,300  of  5,430.\n",
      "  Batch 1,350  of  5,430.\n",
      "  Batch 1,400  of  5,430.\n",
      "  Batch 1,450  of  5,430.\n",
      "  Batch 1,500  of  5,430.\n",
      "  Batch 1,550  of  5,430.\n",
      "  Batch 1,600  of  5,430.\n",
      "  Batch 1,650  of  5,430.\n",
      "  Batch 1,700  of  5,430.\n",
      "  Batch 1,750  of  5,430.\n",
      "  Batch 1,800  of  5,430.\n",
      "  Batch 1,850  of  5,430.\n",
      "  Batch 1,900  of  5,430.\n",
      "  Batch 1,950  of  5,430.\n",
      "  Batch 2,000  of  5,430.\n",
      "  Batch 2,050  of  5,430.\n",
      "  Batch 2,100  of  5,430.\n",
      "  Batch 2,150  of  5,430.\n",
      "  Batch 2,200  of  5,430.\n",
      "  Batch 2,250  of  5,430.\n",
      "  Batch 2,300  of  5,430.\n",
      "  Batch 2,350  of  5,430.\n",
      "  Batch 2,400  of  5,430.\n",
      "  Batch 2,450  of  5,430.\n",
      "  Batch 2,500  of  5,430.\n",
      "  Batch 2,550  of  5,430.\n",
      "  Batch 2,600  of  5,430.\n",
      "  Batch 2,650  of  5,430.\n",
      "  Batch 2,700  of  5,430.\n",
      "  Batch 2,750  of  5,430.\n",
      "  Batch 2,800  of  5,430.\n",
      "  Batch 2,850  of  5,430.\n",
      "  Batch 2,900  of  5,430.\n",
      "  Batch 2,950  of  5,430.\n",
      "  Batch 3,000  of  5,430.\n",
      "  Batch 3,050  of  5,430.\n",
      "  Batch 3,100  of  5,430.\n",
      "  Batch 3,150  of  5,430.\n",
      "  Batch 3,200  of  5,430.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,250  of  5,430.\n",
      "  Batch 3,300  of  5,430.\n",
      "  Batch 3,350  of  5,430.\n",
      "  Batch 3,400  of  5,430.\n",
      "  Batch 3,450  of  5,430.\n",
      "  Batch 3,500  of  5,430.\n",
      "  Batch 3,550  of  5,430.\n",
      "  Batch 3,600  of  5,430.\n",
      "  Batch 3,650  of  5,430.\n",
      "  Batch 3,700  of  5,430.\n",
      "  Batch 3,750  of  5,430.\n",
      "  Batch 3,800  of  5,430.\n",
      "  Batch 3,850  of  5,430.\n",
      "  Batch 3,900  of  5,430.\n",
      "  Batch 3,950  of  5,430.\n",
      "  Batch 4,000  of  5,430.\n",
      "  Batch 4,050  of  5,430.\n",
      "  Batch 4,100  of  5,430.\n",
      "  Batch 4,150  of  5,430.\n",
      "  Batch 4,200  of  5,430.\n",
      "  Batch 4,250  of  5,430.\n",
      "  Batch 4,300  of  5,430.\n",
      "  Batch 4,350  of  5,430.\n",
      "  Batch 4,400  of  5,430.\n",
      "  Batch 4,450  of  5,430.\n",
      "  Batch 4,500  of  5,430.\n",
      "  Batch 4,550  of  5,430.\n",
      "  Batch 4,600  of  5,430.\n",
      "  Batch 4,650  of  5,430.\n",
      "  Batch 4,700  of  5,430.\n",
      "  Batch 4,750  of  5,430.\n",
      "  Batch 4,800  of  5,430.\n",
      "  Batch 4,850  of  5,430.\n",
      "  Batch 4,900  of  5,430.\n",
      "  Batch 4,950  of  5,430.\n",
      "  Batch 5,000  of  5,430.\n",
      "  Batch 5,050  of  5,430.\n",
      "  Batch 5,100  of  5,430.\n",
      "  Batch 5,150  of  5,430.\n",
      "  Batch 5,200  of  5,430.\n",
      "  Batch 5,250  of  5,430.\n",
      "  Batch 5,300  of  5,430.\n",
      "  Batch 5,350  of  5,430.\n",
      "  Batch 5,400  of  5,430.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of  5,430.\n",
      "  Batch   100  of  5,430.\n",
      "  Batch   150  of  5,430.\n",
      "  Batch   200  of  5,430.\n",
      "  Batch   250  of  5,430.\n",
      "  Batch   300  of  5,430.\n",
      "  Batch   350  of  5,430.\n",
      "  Batch   400  of  5,430.\n",
      "  Batch   450  of  5,430.\n",
      "  Batch   500  of  5,430.\n",
      "  Batch   550  of  5,430.\n",
      "  Batch   600  of  5,430.\n",
      "  Batch   650  of  5,430.\n",
      "  Batch   700  of  5,430.\n",
      "  Batch   750  of  5,430.\n",
      "  Batch   800  of  5,430.\n",
      "  Batch   850  of  5,430.\n",
      "  Batch   900  of  5,430.\n",
      "  Batch   950  of  5,430.\n",
      "  Batch 1,000  of  5,430.\n",
      "  Batch 1,050  of  5,430.\n",
      "  Batch 1,100  of  5,430.\n",
      "  Batch 1,150  of  5,430.\n",
      "  Batch 1,200  of  5,430.\n",
      "  Batch 1,250  of  5,430.\n",
      "  Batch 1,300  of  5,430.\n",
      "  Batch 1,350  of  5,430.\n",
      "  Batch 1,400  of  5,430.\n",
      "  Batch 1,450  of  5,430.\n",
      "  Batch 1,500  of  5,430.\n",
      "  Batch 1,550  of  5,430.\n",
      "  Batch 1,600  of  5,430.\n",
      "  Batch 1,650  of  5,430.\n",
      "  Batch 1,700  of  5,430.\n",
      "  Batch 1,750  of  5,430.\n",
      "  Batch 1,800  of  5,430.\n",
      "  Batch 1,850  of  5,430.\n",
      "  Batch 1,900  of  5,430.\n",
      "  Batch 1,950  of  5,430.\n",
      "  Batch 2,000  of  5,430.\n",
      "  Batch 2,050  of  5,430.\n",
      "  Batch 2,100  of  5,430.\n",
      "  Batch 2,150  of  5,430.\n",
      "  Batch 2,200  of  5,430.\n",
      "  Batch 2,250  of  5,430.\n",
      "  Batch 2,300  of  5,430.\n",
      "  Batch 2,350  of  5,430.\n",
      "  Batch 2,400  of  5,430.\n",
      "  Batch 2,450  of  5,430.\n",
      "  Batch 2,500  of  5,430.\n",
      "  Batch 2,550  of  5,430.\n",
      "  Batch 2,600  of  5,430.\n",
      "  Batch 2,650  of  5,430.\n",
      "  Batch 2,700  of  5,430.\n",
      "  Batch 2,750  of  5,430.\n",
      "  Batch 2,800  of  5,430.\n",
      "  Batch 2,850  of  5,430.\n",
      "  Batch 2,900  of  5,430.\n",
      "  Batch 2,950  of  5,430.\n",
      "  Batch 3,000  of  5,430.\n",
      "  Batch 3,050  of  5,430.\n",
      "  Batch 3,100  of  5,430.\n",
      "  Batch 3,150  of  5,430.\n",
      "  Batch 3,200  of  5,430.\n",
      "  Batch 3,250  of  5,430.\n",
      "  Batch 3,300  of  5,430.\n",
      "  Batch 3,350  of  5,430.\n",
      "  Batch 3,400  of  5,430.\n",
      "  Batch 3,450  of  5,430.\n",
      "  Batch 3,500  of  5,430.\n",
      "  Batch 3,550  of  5,430.\n",
      "  Batch 3,600  of  5,430.\n",
      "  Batch 3,650  of  5,430.\n",
      "  Batch 3,700  of  5,430.\n",
      "  Batch 3,750  of  5,430.\n",
      "  Batch 3,800  of  5,430.\n",
      "  Batch 3,850  of  5,430.\n",
      "  Batch 3,900  of  5,430.\n",
      "  Batch 3,950  of  5,430.\n",
      "  Batch 4,000  of  5,430.\n",
      "  Batch 4,050  of  5,430.\n",
      "  Batch 4,100  of  5,430.\n",
      "  Batch 4,150  of  5,430.\n",
      "  Batch 4,200  of  5,430.\n",
      "  Batch 4,250  of  5,430.\n",
      "  Batch 4,300  of  5,430.\n",
      "  Batch 4,350  of  5,430.\n",
      "  Batch 4,400  of  5,430.\n",
      "  Batch 4,450  of  5,430.\n",
      "  Batch 4,500  of  5,430.\n",
      "  Batch 4,550  of  5,430.\n",
      "  Batch 4,600  of  5,430.\n",
      "  Batch 4,650  of  5,430.\n",
      "  Batch 4,700  of  5,430.\n",
      "  Batch 4,750  of  5,430.\n",
      "  Batch 4,800  of  5,430.\n",
      "  Batch 4,850  of  5,430.\n",
      "  Batch 4,900  of  5,430.\n",
      "  Batch 4,950  of  5,430.\n",
      "  Batch 5,000  of  5,430.\n",
      "  Batch 5,050  of  5,430.\n",
      "  Batch 5,100  of  5,430.\n",
      "  Batch 5,150  of  5,430.\n",
      "  Batch 5,200  of  5,430.\n",
      "  Batch 5,250  of  5,430.\n",
      "  Batch 5,300  of  5,430.\n",
      "  Batch 5,350  of  5,430.\n",
      "  Batch 5,400  of  5,430.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of  1,358.\n",
      "  Batch   100  of  1,358.\n",
      "  Batch   150  of  1,358.\n",
      "  Batch   200  of  1,358.\n",
      "  Batch   250  of  1,358.\n",
      "  Batch   300  of  1,358.\n",
      "  Batch   350  of  1,358.\n",
      "  Batch   400  of  1,358.\n",
      "  Batch   450  of  1,358.\n",
      "  Batch   500  of  1,358.\n",
      "  Batch   550  of  1,358.\n",
      "  Batch   600  of  1,358.\n",
      "  Batch   650  of  1,358.\n",
      "  Batch   700  of  1,358.\n",
      "  Batch   750  of  1,358.\n",
      "  Batch   800  of  1,358.\n",
      "  Batch   850  of  1,358.\n",
      "  Batch   900  of  1,358.\n",
      "  Batch   950  of  1,358.\n",
      "  Batch 1,000  of  1,358.\n",
      "  Batch 1,050  of  1,358.\n",
      "  Batch 1,100  of  1,358.\n",
      "  Batch 1,150  of  1,358.\n",
      "  Batch 1,200  of  1,358.\n",
      "  Batch 1,250  of  1,358.\n",
      "  Batch 1,300  of  1,358.\n",
      "  Batch 1,350  of  1,358.\n",
      "saving ...\n",
      "\n",
      "Training Loss: 0.323, Training f1 : 0.8873703423475321\n",
      "Validation Loss: 0.550, Validation f1 : 0.8047112643802619\n",
      "Time for epoch 1 is 42.801793150107066 min\n",
      "\n",
      " Epoch 3 / 3\n",
      "  Batch    50  of  5,430.\n",
      "  Batch   100  of  5,430.\n",
      "  Batch   150  of  5,430.\n",
      "  Batch   200  of  5,430.\n",
      "  Batch   250  of  5,430.\n",
      "  Batch   300  of  5,430.\n",
      "  Batch   350  of  5,430.\n",
      "  Batch   400  of  5,430.\n",
      "  Batch   450  of  5,430.\n",
      "  Batch   500  of  5,430.\n",
      "  Batch   550  of  5,430.\n",
      "  Batch   600  of  5,430.\n",
      "  Batch   650  of  5,430.\n",
      "  Batch   700  of  5,430.\n",
      "  Batch   750  of  5,430.\n",
      "  Batch   800  of  5,430.\n",
      "  Batch   850  of  5,430.\n",
      "  Batch   900  of  5,430.\n",
      "  Batch   950  of  5,430.\n",
      "  Batch 1,000  of  5,430.\n",
      "  Batch 1,050  of  5,430.\n",
      "  Batch 1,100  of  5,430.\n",
      "  Batch 1,150  of  5,430.\n",
      "  Batch 1,200  of  5,430.\n",
      "  Batch 1,250  of  5,430.\n",
      "  Batch 1,300  of  5,430.\n",
      "  Batch 1,350  of  5,430.\n",
      "  Batch 1,400  of  5,430.\n",
      "  Batch 1,450  of  5,430.\n",
      "  Batch 1,500  of  5,430.\n",
      "  Batch 1,550  of  5,430.\n",
      "  Batch 1,600  of  5,430.\n",
      "  Batch 1,650  of  5,430.\n",
      "  Batch 1,700  of  5,430.\n",
      "  Batch 1,750  of  5,430.\n",
      "  Batch 1,800  of  5,430.\n",
      "  Batch 1,850  of  5,430.\n",
      "  Batch 1,900  of  5,430.\n",
      "  Batch 1,950  of  5,430.\n",
      "  Batch 2,000  of  5,430.\n",
      "  Batch 2,050  of  5,430.\n",
      "  Batch 2,100  of  5,430.\n",
      "  Batch 2,150  of  5,430.\n",
      "  Batch 2,200  of  5,430.\n",
      "  Batch 2,250  of  5,430.\n",
      "  Batch 2,300  of  5,430.\n",
      "  Batch 2,350  of  5,430.\n",
      "  Batch 2,400  of  5,430.\n",
      "  Batch 2,450  of  5,430.\n",
      "  Batch 2,500  of  5,430.\n",
      "  Batch 2,550  of  5,430.\n",
      "  Batch 2,600  of  5,430.\n",
      "  Batch 2,650  of  5,430.\n",
      "  Batch 2,700  of  5,430.\n",
      "  Batch 2,750  of  5,430.\n",
      "  Batch 2,800  of  5,430.\n",
      "  Batch 2,850  of  5,430.\n",
      "  Batch 2,900  of  5,430.\n",
      "  Batch 2,950  of  5,430.\n",
      "  Batch 3,000  of  5,430.\n",
      "  Batch 3,050  of  5,430.\n",
      "  Batch 3,100  of  5,430.\n",
      "  Batch 3,150  of  5,430.\n",
      "  Batch 3,200  of  5,430.\n",
      "  Batch 3,250  of  5,430.\n",
      "  Batch 3,300  of  5,430.\n",
      "  Batch 3,350  of  5,430.\n",
      "  Batch 3,400  of  5,430.\n",
      "  Batch 3,450  of  5,430.\n",
      "  Batch 3,500  of  5,430.\n",
      "  Batch 3,550  of  5,430.\n",
      "  Batch 3,600  of  5,430.\n",
      "  Batch 3,650  of  5,430.\n",
      "  Batch 3,700  of  5,430.\n",
      "  Batch 3,750  of  5,430.\n",
      "  Batch 3,800  of  5,430.\n",
      "  Batch 3,850  of  5,430.\n",
      "  Batch 3,900  of  5,430.\n",
      "  Batch 3,950  of  5,430.\n",
      "  Batch 4,000  of  5,430.\n",
      "  Batch 4,050  of  5,430.\n",
      "  Batch 4,100  of  5,430.\n",
      "  Batch 4,150  of  5,430.\n"
     ]
    }
   ],
   "source": [
    "learn(train_dataloader, val_dataloader, modules, hyperparameters, experiment_name=\"seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sFrTIAKAkd6Y"
   },
   "outputs": [],
   "source": [
    "#load weights of best model\n",
    "path = 'mlruns/3/99d47e8c01ff44168492fcde69cf75ce/artifacts/model_checkpoint/data/model.pth'\n",
    "model= torch.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1358/1358 [02:29<00:00,  9.07it/s]\n"
     ]
    }
   ],
   "source": [
    "total_preds = []\n",
    "total_labels = []\n",
    "for batch in tqdm(val_dataloader):\n",
    "    preds = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
    "    preds = preds.logits.detach().cpu().numpy()\n",
    "    total_preds.append(preds)\n",
    "    total_labels.append(batch['labels'])\n",
    "    del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate(total_preds)\n",
    "labels = np.concatenate(total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(y_pred,axis=1)  \n",
    "# labels = np.concatenate(total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8944990577520359"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(labels,preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212520671445632"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8212520671445632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = NlpTestDataset(test_df,tokenizer)\n",
    "test_dataloader = DataLoader(testdata, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1697/1697 [03:14<00:00,  8.72it/s]\n"
     ]
    }
   ],
   "source": [
    "total_preds = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    preds = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
    "    preds = preds.logits.detach().cpu().numpy()\n",
    "    total_preds.append(preds)\n",
    "    del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(np.concatenate(total_preds),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  388.,     0.,   952.,     0.,   273.,     0.,  2258.,     0.,\n",
       "          191.,     0.,  1084.,     0.,  3008.,     0.,   216.,     0.,\n",
       "         1580.,     0.,     0.,   736.,     0.,   207.,     0.,  2700.,\n",
       "            0.,   399.,     0.,   871.,     0.,  2994.,     0.,  1091.,\n",
       "            0.,  1449.,     0.,   326.,     0.,     0.,  1016.,     0.,\n",
       "        18186.,     0.,  3748.,     0.,   199.,     0.,  2506.,     0.,\n",
       "          200.,     0.,  1505.,     0.,   886.,     0.,  4798.,     0.,\n",
       "          533.]),\n",
       " array([ 0.        ,  0.47368421,  0.94736842,  1.42105263,  1.89473684,\n",
       "         2.36842105,  2.84210526,  3.31578947,  3.78947368,  4.26315789,\n",
       "         4.73684211,  5.21052632,  5.68421053,  6.15789474,  6.63157895,\n",
       "         7.10526316,  7.57894737,  8.05263158,  8.52631579,  9.        ,\n",
       "         9.47368421,  9.94736842, 10.42105263, 10.89473684, 11.36842105,\n",
       "        11.84210526, 12.31578947, 12.78947368, 13.26315789, 13.73684211,\n",
       "        14.21052632, 14.68421053, 15.15789474, 15.63157895, 16.10526316,\n",
       "        16.57894737, 17.05263158, 17.52631579, 18.        , 18.47368421,\n",
       "        18.94736842, 19.42105263, 19.89473684, 20.36842105, 20.84210526,\n",
       "        21.31578947, 21.78947368, 22.26315789, 22.73684211, 23.21052632,\n",
       "        23.68421053, 24.15789474, 24.63157895, 25.10526316, 25.57894737,\n",
       "        26.05263158, 26.52631579, 27.        ]),\n",
       " <BarContainer object of 57 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(preds,bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_df['Id']\n",
    "submission['Category'] = preds\n",
    "submission.to_csv('b7627288e1244ad0bdb90c4aad8ec02d.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271476</th>\n",
       "      <td>54295</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271477</th>\n",
       "      <td>54296</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271482</th>\n",
       "      <td>54297</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271485</th>\n",
       "      <td>54298</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271486</th>\n",
       "      <td>54299</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  Category\n",
       "3           0         6\n",
       "6           1        20\n",
       "11          2        19\n",
       "17          3        19\n",
       "18          4        19\n",
       "...       ...       ...\n",
       "271476  54295        19\n",
       "271477  54296        12\n",
       "271482  54297        19\n",
       "271485  54298        26\n",
       "271486  54299        15\n",
       "\n",
       "[54300 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adil/anaconda3/envs/ma-gym/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from math import inf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOiFO7kH8BNJnrr5sQt7ela",
   "collapsed_sections": [],
   "mount_file_id": "1kUrM1YVCeGVysEaGY6DaOnx8EG1oho0T",
   "name": "defi_ia_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('ma-gym': conda)",
   "language": "python",
   "name": "python37964bitmagymcondad4f0966e43384e928899b2eef06108e5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "068aa434c73a48248a247bf3bb00219e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0869726f74204fe898f99523abcc1121": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de1a481186884024bd7157dfbb310b3e",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eea2477986584b27998809147e6516b6",
      "value": 440473133
     }
    },
    "307834e91d584b2f9d55e5d381d0d31c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34a342d97640460b908d872874c547c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e114e39bf66b4b92ad1465dd0ae76ea8",
      "placeholder": "​",
      "style": "IPY_MODEL_6f200e0903b44bbea01df7dde02b9a65",
      "value": " 440M/440M [10:15&lt;00:00, 716kB/s]"
     }
    },
    "4b46df27e84343a6ac2a27847645a863": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "627719943ff94ab39c1f5560d3a0a1dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "681fdd42ad9448b68ad5b665dc6d1857": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0869726f74204fe898f99523abcc1121",
       "IPY_MODEL_34a342d97640460b908d872874c547c0"
      ],
      "layout": "IPY_MODEL_307834e91d584b2f9d55e5d381d0d31c"
     }
    },
    "6f200e0903b44bbea01df7dde02b9a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7859513cebd24a3eaab1cbd63da0e24c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9223b8a8577641e2b361437bc4e23555": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f67ebf385e09474db0b1b2817591944c",
      "placeholder": "​",
      "style": "IPY_MODEL_627719943ff94ab39c1f5560d3a0a1dc",
      "value": " 433/433 [00:00&lt;00:00, 849B/s]"
     }
    },
    "d51ed6dc16d24ab491a6ec33d5ab7250": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_068aa434c73a48248a247bf3bb00219e",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b46df27e84343a6ac2a27847645a863",
      "value": 433
     }
    },
    "de1a481186884024bd7157dfbb310b3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e114e39bf66b4b92ad1465dd0ae76ea8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eea2477986584b27998809147e6516b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f20931b8c05142efaf97886e434435ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d51ed6dc16d24ab491a6ec33d5ab7250",
       "IPY_MODEL_9223b8a8577641e2b361437bc4e23555"
      ],
      "layout": "IPY_MODEL_7859513cebd24a3eaab1cbd63da0e24c"
     }
    },
    "f67ebf385e09474db0b1b2817591944c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
